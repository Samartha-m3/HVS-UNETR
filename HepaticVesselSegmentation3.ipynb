{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Normalize and Window Transforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "from monai.transforms import MapTransform\n",
    "from monai.config import KeysCollection\n",
    "class MinMax(MapTransform):\n",
    "\tdef __init__(self, keys: KeysCollection, allow_missing_keys: bool = False):\n",
    "\t\tsuper().__init__(keys=keys, allow_missing_keys=allow_missing_keys)\n",
    "\n",
    "\tdef normalize(self, data: monai.data.MetaTensor):\n",
    "\t\tmin = data.min()\n",
    "\t\tmax = data.max()\n",
    "\t\tif max > min:\n",
    "\t\t\tdata = (data - min) / (max - min)\n",
    "\t\telif max == min:\n",
    "\t\t\tdata = (data - min) / max\n",
    "\t\telse:\n",
    "\t\t\traise ValueError('MinMax failed: Minimum seems to be greater than maximum')\n",
    "\t\treturn data\n",
    "\n",
    "\tdef __call__(self, data):\n",
    "\t\tfor key in self.keys:\n",
    "\t\t\tif key in data:\n",
    "\t\t\t\tdata[key] = self.normalize(data[key])\n",
    "\t\treturn data\n",
    "\n",
    "class Window(MapTransform):\n",
    "\tdef __init__(self, window_center: float, window_width: float, keys: KeysCollection, allow_missing_keys: bool = False):\n",
    "\t\tsuper().__init__(keys=keys, allow_missing_keys=allow_missing_keys)\n",
    "\t\tself.window_center = window_center\n",
    "\t\tself.window_width = window_width\n",
    "\n",
    "\tdef window(self, data: monai.data.MetaTensor):\n",
    "\t\timg_min = self.window_center - self.window_width // 2\n",
    "\t\timg_max = self.window_center + self.window_width // 2\n",
    "\t\tdata[data < img_min] = img_min\n",
    "\t\tdata[data > img_max] = img_max\n",
    "\t\treturn data\n",
    "\n",
    "\tdef __call__(self, data):\n",
    "\t\tfor key in self.keys:\n",
    "\t\t\tif key in data:\n",
    "\t\t\t\tdata[key] = self.window(data[key])\n",
    "\t\treturn data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2l4y9WJ8z5-"
   },
   "source": [
    "### Setup transforms for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5WT5GKok8z5-"
   },
   "outputs": [],
   "source": [
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    EnsureChannelFirstd,\n",
    "    SpatialPadD,\n",
    "    Resized,\n",
    "    RandFlipd,\n",
    "    RandRotate90d,\n",
    "    RandShiftIntensityd,\n",
    ")\n",
    "\n",
    "root_dir = '/home/samartha-mig/Projects/monai_prac_3d/Seg3'\n",
    "\n",
    "volume_size = (224, 224, 224)\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=['image', 'label']),\n",
    "        EnsureChannelFirstd(keys=['image', 'label']),\n",
    "        # Window(keys=[\"image\"], window_center=150, window_width=500),\n",
    "        SpatialPadD(\n",
    "        keys=['image', 'label'],\n",
    "        spatial_size=(512, 512, 256)\n",
    "        ),\n",
    "        Resized(\n",
    "        keys=['image', 'label'],\n",
    "        spatial_size=volume_size,\n",
    "        mode=('bilinear', 'nearest')\n",
    "        ),\n",
    "        # Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        # Spacingd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     pixdim=(1.5, 1.5, 2.0),\n",
    "        #     mode=(\"bilinear\", \"nearest\"),\n",
    "        # ),\n",
    "        # ScaleIntensityRanged(\n",
    "        #     keys=[\"image\"],\n",
    "        #     a_min=-175,\n",
    "        #     a_max=250,\n",
    "        #     b_min=0.0,\n",
    "        #     b_max=1.0,\n",
    "        #     clip=True,\n",
    "        # ),\n",
    "        # CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        # RandCropByPosNegLabeld(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     label_key=\"label\",\n",
    "        #     spatial_size=(96, 96, 96),\n",
    "        #     pos=1,\n",
    "        #     neg=1,\n",
    "        #     num_samples=4,\n",
    "        #     image_key=\"image\",\n",
    "        #     image_threshold=0,\n",
    "        # ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[0],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[1],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandFlipd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            spatial_axis=[2],\n",
    "            prob=0.10,\n",
    "        ),\n",
    "        RandRotate90d(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            prob=0.10,\n",
    "            max_k=3,\n",
    "        ),\n",
    "        RandShiftIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            offsets=0.10,\n",
    "            prob=0.50,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        SpatialPadD(\n",
    "        keys=['image', 'label'],\n",
    "        spatial_size=(512, 512, 256)\n",
    "        ),\n",
    "        Resized(\n",
    "        keys=['image', 'label'],\n",
    "        spatial_size=volume_size,\n",
    "        mode=('bilinear', 'nearest')\n",
    "        ),\n",
    "        # Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        # Spacingd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     pixdim=(1.5, 1.5, 2.0),\n",
    "        #     mode=(\"bilinear\", \"nearest\"),\n",
    "        # ),\n",
    "        # ScaleIntensityRanged(keys=[\"image\"], a_min=-175, a_max=250, b_min=0.0, b_max=1.0, clip=True),\n",
    "        # CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WT5GKok8z5-"
   },
   "source": [
    "### Setting up Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lEBkxvqJ8z5_"
   },
   "outputs": [],
   "source": [
    "from monai.data import DataLoader\n",
    "from monai.data.dataset import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import json\n",
    "data_dir = \"/home/samartha-mig/Projects/data/Task08_HepaticVessel\"\n",
    "files = json.load(open(os.path.join(data_dir, 'dataset.json')))['training']\n",
    "for file in files:\n",
    "  for key in file.keys():\n",
    "    file[key] = os.path.join(data_dir, file[key].replace('./', ''))\n",
    "train_list, val_list = train_test_split(files, train_size=0.7)\n",
    "train_ds = Dataset(data=train_list, transform=train_transforms)\n",
    "val_ds = Dataset(data=val_list, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=5, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=5, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86Ga2YMr8z5_"
   },
   "source": [
    "### Create Model, Loss, Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QZxuM1Ny8z6A"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from monai.networks.nets.unetr import UNETR\n",
    "from monai.losses.dice import DiceCELoss\n",
    "device = \"cuda:1\"\n",
    "\n",
    "model = UNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=3,\n",
    "    img_size=volume_size,\n",
    "    feature_size=16,\n",
    "    hidden_size=768,\n",
    "    mlp_dim=3072,\n",
    "    num_heads=12,\n",
    "    proj_type=\"conv\",\n",
    "    norm_name=\"instance\",\n",
    "    res_block=True,\n",
    "    dropout_rate=0.0,\n",
    ").to(device)\n",
    "\n",
    "loss_function = DiceCELoss(\n",
    "    include_background = False,\n",
    "    to_onehot_y=True,\n",
    "    softmax=True\n",
    ")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piKxqGTr8z6A"
   },
   "source": [
    "### Execute a typical PyTorch training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PtnBP_it8z6A",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (113 / 21200 Steps) (loss=1.54195):  54%|█████▍    | 114/212 [05:33<03:11,  1.95s/it]"
     ]
    }
   ],
   "source": [
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import AsDiscrete\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.data import decollate_batch\n",
    "from tqdm import tqdm\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "def validation(epoch_iterator_val):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in epoch_iterator_val:\n",
    "            val_inputs, val_labels = (batch[\"image\"].to(device), batch[\"label\"].to(device))\n",
    "            val_outputs = sliding_window_inference(val_inputs, volume_size, 4, model)\n",
    "            val_labels_list = decollate_batch(val_labels)\n",
    "            val_labels_convert = [post_label(val_label_tensor) for val_label_tensor in val_labels_list]\n",
    "            val_outputs_list = decollate_batch(val_outputs)\n",
    "            val_output_convert = [post_pred(val_pred_tensor) for val_pred_tensor in val_outputs_list]\n",
    "            dice_metric(y_pred=val_output_convert, y=val_labels_convert)\n",
    "            epoch_iterator_val.set_description(\"Validate (%d / %d Steps)\" % (global_step, 10.0))  # noqa: B038\n",
    "        mean_dice_val = dice_metric.aggregate().item()\n",
    "        dice_metric.reset()\n",
    "    return mean_dice_val\n",
    "\n",
    "def train(global_step, train_loader, dice_val_best, global_step_best):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    epoch_iterator = tqdm(train_loader) # , desc=\"Training (X / X Steps) (loss=X.X)\", dynamic_ncols=True\n",
    "    for step, batch in enumerate(epoch_iterator):\n",
    "        step += 1\n",
    "        x, y = (batch[\"image\"].to(device), batch[\"label\"].to(device))\n",
    "        logit_map = model(x)\n",
    "        loss = loss_function(logit_map, y)\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_iterator.set_description(  # noqa: B038\n",
    "            \"Training (%d / %d Steps) (loss=%2.5f)\" % (global_step, max_iterations, loss)\n",
    "        )\n",
    "        if (global_step % eval_num == 0 and global_step != 0) or global_step == max_iterations:\n",
    "            epoch_iterator_val = tqdm(val_loader) # , desc=\"Validate (X / X Steps) (dice=X.X)\", dynamic_ncols=True\n",
    "            dice_val = validation(epoch_iterator_val)\n",
    "            epoch_loss /= step\n",
    "            epoch_loss_values.append(epoch_loss)\n",
    "            metric_values.append(dice_val)\n",
    "            if dice_val > dice_val_best:\n",
    "                dice_val_best = dice_val\n",
    "                global_step_best = global_step\n",
    "                torch.save(model.state_dict(), os.path.join(root_dir, \"best_metric_model.pth\"))\n",
    "                print(\n",
    "                    \"Model Was Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(dice_val_best, dice_val)\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    \"Model Was Not Saved ! Current Best Avg. Dice: {} Current Avg. Dice: {}\".format(\n",
    "                        dice_val_best, dice_val\n",
    "                    )\n",
    "                )\n",
    "        global_step += 1\n",
    "    return global_step, dice_val_best, global_step_best\n",
    "\n",
    "\n",
    "max_iterations = 21200\n",
    "eval_num = 1060\n",
    "post_label = AsDiscrete(to_onehot=3)\n",
    "post_pred = AsDiscrete(argmax=True, to_onehot=3)\n",
    "dice_metric = DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "global_step = 0\n",
    "dice_val_best = 0.0\n",
    "global_step_best = 0\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "while global_step < max_iterations:\n",
    "    global_step, dice_val_best, global_step_best = train(global_step, train_loader, dice_val_best, global_step_best)\n",
    "model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefile = open(os.path.join(root_dir, 'savefile.json'), 'w')\n",
    "json.dump(\n",
    "    {\n",
    "        'dice_val_best':dice_val_best,\n",
    "        'global_step_best':global_step_best,\n",
    "        'epoch_loss_values':epoch_loss_values,\n",
    "        'metric_values':metric_values\n",
    "    },\n",
    "    savefile\n",
    ")\n",
    "savefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MMNr07Ww8z6A"
   },
   "outputs": [],
   "source": [
    "print(f\"train completed, best_metric: {dice_val_best:.4f} \" f\"at iteration: {global_step_best}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
